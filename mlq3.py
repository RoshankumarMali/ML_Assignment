# -*- coding: utf-8 -*-
"""MLQ3new.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e_XXuX4mez7U_nrzbKZz0Pt6K9s_kUNJ
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
import pandas as pd
from matplotlib import pyplot as plt
# %matplotlib inline
import os
import cv2
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, Dropout
from PIL import Image
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
import seaborn as sns

#Define the paths to your image and csv folders
train_val_dir = "/content/drive/MyDrive/MLassignment/charts/train_val"
test_dir = "/content/drive/MyDrive/MLassignment/charts/test"
train_path_labels = "/content/drive/MyDrive/MLassignment/charts/train_val.csv"
train_val_labels = pd.read_csv('/content/drive/MyDrive/MLassignment/charts/train_val.csv')

images = []
labels = []
for subdir, _, files in os.walk(train_val_dir):
    for file in files:
        if file.endswith('.png'):
            # Load the images and resize them to (224, 224) with 3 color channels
            img = Image.open(os.path.join(subdir, file)).resize((224, 224)).convert('RGB')
            img_array = np.array(img)
            # Append the array to the list of images
            images.append(img_array)
            # Append the corresponding label
            labels.append(subdir.split('/')[-1])
        
# Convert the string labels to numerical labels
le = LabelEncoder()
labels = le.fit_transform(labels)

# Convert the lists to NumPy arrays
images = np.array(images)
labels = np.array(labels)

# Save the arrays in NumPy format
np.save('x_train.npy', images)
np.save('y_train.npy', labels)

x_train = np.load('x_train.npy') 
y_train = np.load('y_train.npy')

print(x_train.shape)
print(y_train.shape)

# Get a list of all the image filenames in the training directory
filenames = [filename for filename in os.listdir(test_dir) if filename.endswith('.png')]

# Initialize empty lists for the images and labels
images_test = []
labels_test = []

# Loop through the filenames
for filename in filenames:
    # Load the image using PIL
    img = Image.open(os.path.join(test_dir, filename)).resize((224, 224)).convert('RGB')
    
    # Resize the image to (224, 224) with 3 color channels
    img = img.resize((224, 224))
    
    # Convert the image to a NumPy array
    img_array = np.array(img)
    
    # Append the array to the list of images
    images_test.append(img_array)
    
    # Append the filename (without the '.png' extension) to the list of labels
    labels_test.append(filename[:-4])

# Convert the string labels to numerical labels
le = LabelEncoder()
labels = le.fit_transform(labels)

# Convert the lists to NumPy arrays
images_test = np.array(images_test)
labels_test = np.array(labels_test)

# Save the arrays in NumPy format
np.save('x_test.npy', images_test)
np.save('y_test.npy', labels_test)

# Load the arrays from the saved files
x_test = np.load('x_test.npy')
y_test = np.load('y_test.npy')

print(x_test.shape)
print(y_test.shape)

# check the images loaded
plt.figure(figsize = (15,4))
plt.matshow(x_train[20])
plt.matshow(x_train[999])

# define some classes from the images we have observed
image_classes = ['line', 'dot_line', 'hbar_categorical', 'vbar_categorical', 'pie']
image_classes[0]

# create a LabelEncoder object and fit it on the list of classes
le = LabelEncoder()
le.fit(image_classes)

# map the categories to the labels array
#y_train = le.transform(train_val_labels['type'])
#y_test = le.transform(test_labels['type'])
label_map = {'line': 0, 'dot_line': 1, 'hbar_categorical': 2, 'vbar_categorical': 3, 'pie': 4}
y_train = np.array([label_map[label] for label in train_val_labels['type']])

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

# we need to map the lables from csv to the images somehow
# function to test the chart sample
def image_sample(x, y, index):
 plt.figure(figsize = (15,4))
 plt.imshow(x[index])

 plt.xlabel(image_classes[y[index]])
image_sample(x_train,y_train,130)
image_sample(x_train,y_train,509)
image_sample(x_train,y_train,890)

# now we have mapped the corresponding labels to the image
# normalize the image

x_train=x_train /255
x_test=x_test /255

# take the label for train data from csv file
y_train_index = train_val_labels['image_index']
y_train_type = train_val_labels['type']

print(x_train.shape)
print(x_test.shape)

# Set random seed for reproducibility
np.random.seed(42)

# Shuffle the indices of the training images
indices = np.random.permutation(len(x_train))

# Split the indices into training and validation sets
train_indices = indices[:int(0.8 * len(indices))]
val_indices = indices[int(0.8 * len(indices)):]

# Use the training and validation indices to split the images and labels
x_train, x_val = x_train[train_indices], x_train[val_indices]
y_train, y_val = y_train[train_indices], y_train[val_indices]

# Split the training images and labels into training and validation sets
x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)

# writing a simple CNN to test first
# Define the model architecture
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(5, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Fit the model
#history = model.fit(x_train, y_train, epochs=15)
history = model.fit(x_train, y_train, epochs=30,validation_data=(x_test, y_test))

# Plot the obtained loss
plt.plot(history.history['loss'], linestyle='--')
plt.plot(history.history['val_loss'],linestyle='--')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()

model.evaluate(x_test,y_test)

#sample of the Test data
print("Sample of the Test data:")
image_sample(x_test,y_test,32)
image_sample(x_test,y_test,49)
image_sample(x_test,y_test,26)
image_sample(x_test,y_test,5)

#Observation: we can see some wrong predictions

y_pred = model.predict(x_test)
#print(y_pred[:5])

y_classes = [np.argmax(element) for element in y_pred]
print("1st 5 sample from y_class" , y_classes[:5])
print("1st 5 sample from y_test" , y_test[:5])

# here we see some values are not matching and some value are matching so we are going to check the classification report.
print("classification report: \n", classification_report(y_test,y_classes))

# Generate the confusion matrix 
conf_mat = confusion_matrix(y_test, y_classes)
print('Confusion Matrix:')
print(conf_mat)

# Plot the confusion matrix using Seaborn heatmap
sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""#Finetune the model"""

import tensorflow as tf
from tensorflow.keras.applications import VGG16

#Load the pre-trained model
vgg16_model = VGG16(
weights='imagenet',
include_top=False,
input_shape=(224, 224, 3),
pooling='max'
)

#Freeze the layers of the pre-trained model
for layer in vgg16_model.layers:
  layer.trainable = False

#Print the summary of the pre-trained model
vgg16_model.summary()

# Set up data generators for image augmentation and feeding data to the model
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
test_datagen = ImageDataGenerator(rescale=1./255)

# Fit the generators to the data
train_datagen.fit(x_train)
test_datagen.fit(x_test)


# Generate augmented data in batches
train_generator = train_datagen.flow(
    x_train, y_train,
    batch_size=32,
    shuffle=True
)
test_generator = test_datagen.flow(
    x_test, y_test,
    batch_size=32,
    shuffle=False
)

#Train the model with early stopping
from tensorflow.keras.callbacks import EarlyStopping

es = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)
history = model.fit(train_generator, epochs=100, validation_data=test_generator, callbacks=[es])

#Plot the training and validation accuracy
plt.plot(history.history['accuracy'], label='train')
plt.plot(history.history['val_accuracy'], label='val')
plt.title('Training and validation accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.show()