# -*- coding: utf-8 -*-
"""MLQ2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y7vOYO4pZfyy8_yt76lT2FRzxLbREq9a
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import pandas as pd
from matplotlib import pyplot as plt
# %matplotlib inline
import os
import cv2

from google.colab import drive 
drive.mount('/content/drive/')

# Define the paths to your image folders
train_folder_path = '/content/drive/MyDrive/MLassignment/train'
val_folder_path = '/content/drive/MyDrive/MLassignment/val'

# Set the image size
img_size = (28, 28)

# Define an instance of the ImageDataGenerator class
data_generator = ImageDataGenerator(
    rescale=1./255,      # Rescale pixel values to [0, 1]
    validation_split=0.2, # Split the data into training and validation sets
)

# Load the training data as a generator
train_generator = data_generator.flow_from_directory(
    train_folder_path,           # Directory containing the images
    target_size=img_size, # Resize the images to img_size
    batch_size=32,      # Number of images in each batch
    color_mode='grayscale', # Convert the images to grayscale
    class_mode='categorical', # Use categorical labels
    subset='training', # Use the training subset of the data
    shuffle=True,      # Shuffle the images
    seed=42,           # Set the random seed for reproducibility
)

# Extract the images and labels from the generators
images, labels = [], []
for x, y in train_generator:
    images.extend(x)
    labels.extend(y.argmax(axis=1))
    if len(images) >= train_generator.n:
        break

#Alternate Methode of reading and importing the data 
# Set the path to the folder containing the 'val' folder
val_dir = val_folder_path

# Set the image size
img_size_val = (28, 28)

# Create an empty list to hold the image-label pairs
data_val = []

# Loop over each folder from '0' to '9'
for label in range(10):
    folder_path = os.path.join(val_dir, str(label))

    # Loop over each image in the folder
    for file in os.listdir(folder_path):
        file_path = os.path.join(folder_path, file)
        if file_path.endswith(('.tiff','.bmp')):
            # Load the image and resize it to the desired size
            img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
            img = cv2.resize(img, img_size_val)
            # Append the image-label pair to the list
            data_val.append((img, label))

# Shuffle the data
np.random.shuffle(data_val)

# Separate the images and labels into separate arrays
images_val = np.array([x[0] for x in data_val])
labels_val = np.array([x[1] for x in data_val])

# Save the arrays in NumPy format
np.savez('dataset_val.npz', images=images_val, labels=labels_val)

# Convert the lists to NumPy arrays
images_train = np.asarray(images)
labels_train = np.asarray(labels)
images_val = np.array([x[0] for x in data_val])
labels_val = np.array([x[1] for x in data_val])

# Save the arrays in NumPy format
np.savez('dataset_train.npz', images=images_train, labels=labels_train)
np.savez('dataset_val.npz', images=images_val, labels=labels_val)

# Load the NumPy archive files
dataset_train = np.load('dataset_train.npz')
dataset_test = np.load('dataset_val.npz')

# Extract the images and labels from the archive files
x_train = dataset_train['images']
y_train = dataset_train['labels']
x_test = dataset_test['images']
y_test = dataset_test['labels']

# Print the shape of the arrays
print('Number of training images:', len(x_train))
print('Number of test images:', len(x_test))
print(f'x_train shape: {x_train.shape}')
print(f'y_train shape: {y_train.shape}')
print(f'x_test shape: {x_test.shape}')
print(f'y_test shape: {y_test.shape}')

# Display an image from the dataset

plt.matshow(x_train[10], cmap='gray')
plt.matshow(x_train[799], cmap='gray')
plt.matshow(x_test[140], cmap='gray')
plt.show()

x_train_flat = x_train.reshape(x_train.shape[0], -1)
x_test_flat = x_test.reshape(x_test.shape[0], -1)
print('Training dataset shape:', x_train_flat.shape)
print('Test dataset shape:', x_test_flat.shape)
print('First 10 elements of the first training image:', x_train_flat[0][:10])

"""# Creating a simple Neural Network"""

# Scale the input data
x_train_scaled = x_train/255
x_test_scaled = x_test/255

# Define the neural network architecture
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)), # Flatten the input images
    keras.layers.Dense(10, activation='sigmoid') # Add a fully connected layer with 10 output units
])

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))

# evaluate test dataset
model.evaluate(x_test_scaled,y_test)

#predict the first image
plt.matshow(x_test[5],cmap='gray')
y_predicted = model.predict(x_test_scaled)
predicted_value = np.argmax(y_predicted[5])
print(f"Predicted value is {predicted_value}")

#test some more values
plt.matshow(x_test[53],cmap='gray')
predicted_value = np.argmax(y_predicted[53])
print(f"Predicted value is {predicted_value}")

plt.matshow(x_test[177],cmap='gray')
predicted_value = np.argmax(y_predicted[177])
print(f"Predicted value is {predicted_value}")

from sklearn.metrics import confusion_matrix
y_predicted_labels = np.argmax(y_predicted, axis=1)
conf_mat = confusion_matrix(y_test, y_predicted_labels)
print(conf_mat)

import seaborn as sn

plt.figure(figsize=(10, 10))
sn.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

#Evaluate the model
test_loss, test_acc = model.evaluate(x_test, y_test)
print('Test accuracy:', test_acc)

#Plot the training and validation accuracy
accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
epochs = range(len(accuracy))

plt.figure(figsize=(10, 6))
plt.bar(epochs, accuracy, color='blue', alpha=0.5)
plt.bar(epochs, val_accuracy, color='orange', alpha=0.5)
plt.title('Model accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'])
plt.show()